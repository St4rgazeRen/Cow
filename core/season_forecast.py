"""
core/season_forecast.py  Â·  v1.3
å››å­£ç†è«–ç›®æ¨™åƒ¹é æ¸¬ç³»çµ±
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ç‰ˆæ¬¡è¨˜éŒ„:
  v1.0  åˆç‰ˆï¼Œç´”æ™‚é–“å­£ç¯€ï¼ˆæ¸›åŠå¾Œæœˆä»½åˆ¤æ–·ï¼‰
  v1.1  ä¿®æ­£ add_vline å­—ä¸² x åº§æ¨™ TypeError
  v1.2  æ–°å¢å¸‚å ´ç‹€æ…‹æ ¡æ­£å±¤ï¼ˆanalyze_market_state / _derive_real_seasonï¼‰
  v1.3  [æœ¬æ¬¡] ä¿®æ­£ä»¥ä¸‹å•é¡Œï¼š
        â‘  analyze_market_state: df.index tz-aware vs naive datetime æ¯”è¼ƒéŒ¯èª¤
          â†’ mask_cycle / mask_prev å…¨éƒ¨æ”¹ç”¨ tz æ¨™æº–åŒ–å¾Œæ¯”è¼ƒ
          â†’ å°è‡´ cycle_ath å–åˆ°å…¨ df maxï¼ˆåé«˜ï¼‰ï¼Œç†Šå¸‚ç›®æ¨™åƒ¹ç®—éŒ¯
        â‘¡ forecast_price: prev_ath ä¹ŸåŠ  tz æ¨™æº–åŒ–ä¿è­·
        â‘¢ CYCLE_HISTORY: æ–°å¢ç¬¬4é€±æœŸå·²çŸ¥æ•¸æ“šï¼ˆATH=$108,268ï¼Œ2025-01-20ï¼‰
          æ¨™è¨˜ is_complete=Falseï¼ŒF4 è¡¨æ ¼é¡¯ç¤ºã€Œé€²è¡Œä¸­ã€è€Œéã€Œé æ¸¬ã€
        â‘£ ç†Šå¸‚å¡ç‰‡æ¨™ç±¤ï¼šæ”¹ç‚ºã€Œæœ€æ·±ç›®æ¨™/ä¸­ä½æ•¸ç›®æ¨™/æœ€æ·ºç›®æ¨™ã€æ¶ˆé™¤æ­§ç¾©
        â‘¤ get_cycle_comparison_table: ç¬¬4é€±æœŸé¡¯ç¤ºå·²çŸ¥ATH + ç‹€æ…‹æ¨™è¨˜
        â‘¥ F3 åœ–èªªæ–°å¢å†ªå¾‹æ¨¡å‹èªªæ˜ README

å†ªå¾‹æ¨¡å‹èªªæ˜:
  å…¬å¼ï¼šPrice = 10^(-17.01467 + 5.84 Ã— log10(days_since_genesis))
  ä¾†æºï¼šGiovanni Santostasiã€Œæ¯”ç‰¹å¹£å†ªå¾‹ç†è«–ã€
  ç”¨é€”ï¼šé•·æœŸå…¬å…åƒ¹å€¼ä¼°ç®—ï¼ŒéçŸ­æœŸç›®æ¨™åƒ¹
  èµ°å»Šï¼šÂ±0.45 log10 = ç´„ Â±2.8 å€ï¼ˆå«è“‹æ­·å² 95% ä»¥ä¸Šçš„æ—¥ç·šæ”¶ç›¤ï¼‰
  é‡è¦ï¼šå†ªå¾‹æ¨¡å‹æ˜¯é•·æœŸè¶¨å‹¢ï¼Œä¸ä»£è¡¨çŸ­æœŸæœƒåˆ°é”è©²åƒ¹æ ¼
        ç†Šå¸‚å ´æ™¯ä¸‹ï¼Œå¯¦éš›åƒ¹æ ¼å¯èƒ½å¤§å¹…ä½æ–¼å†ªå¾‹å…¬å…åƒ¹å€¼

æ­·å²æ¸›åŠæ—¥:
  Halving 1: 2012-11-28
  Halving 2: 2016-07-09
  Halving 3: 2020-05-11
  Halving 4: 2024-04-19  â† å·²ç™¼ç”Ÿï¼ŒATH $108,268 (2025-01-20ï¼Œé€²è¡Œä¸­)
  Halving 5: ~2028-04-17 (é ä¼°)

ç´” Pythonï¼Œç„¡ Streamlit ä¾è³´
"""

from datetime import datetime, timedelta, timezone
import numpy as np
import pandas as pd


HALVING_DATES = [
    datetime(2012, 11, 28),
    datetime(2016, 7,   9),
    datetime(2020, 5,  11),
    datetime(2024, 4,  19),
    datetime(2028, 4,  17),
]

CYCLE_HISTORY = [
    {
        "halving":       datetime(2012, 11, 28),
        "halving_price": 12.35,
        "ath_price":     1163.0,
        "ath_date":      datetime(2013, 11, 29),
        "bear_low":      152.40,
        "bear_low_date": datetime(2015, 1, 14),
        "peak_mult":     94.2,
        "bottom_mult":   0.131,   # 152.40 / 1163.0
        "peak_days":     366,
        "bottom_days":   777,
        "is_complete":   True,
    },
    {
        "halving":       datetime(2016, 7, 9),
        "halving_price": 650.0,
        "ath_price":     19891.0,
        "ath_date":      datetime(2017, 12, 17),
        "bear_low":      3122.0,
        "bear_low_date": datetime(2018, 12, 15),
        "peak_mult":     30.6,
        "bottom_mult":   0.157,   # 3122 / 19891
        "peak_days":     526,
        "bottom_days":   889,
        "is_complete":   True,
    },
    {
        "halving":       datetime(2020, 5, 11),
        "halving_price": 8571.0,
        "ath_price":     68789.0,
        "ath_date":      datetime(2021, 11, 10),
        "bear_low":      15476.0,
        "bear_low_date": datetime(2022, 11, 21),
        "peak_mult":     8.03,
        "bottom_mult":   0.225,   # 15476 / 68789
        "peak_days":     549,
        "bottom_days":   925,
        "is_complete":   True,
    },
    {
        # â”€â”€ ç¬¬4é€±æœŸï¼šå·²çŸ¥éƒ¨åˆ†æ•¸æ“šï¼ˆATH å·²ç™¼ç”Ÿï¼Œç†Šå¸‚åº•éƒ¨å°šæœªå®Œæˆï¼‰â”€â”€
        "halving":       datetime(2024, 4, 19),
        "halving_price": 63842.0,           # 2024-04-19 æ”¶ç›¤
        "ath_price":     108268.0,           # 2025-01-20 æ”¶ç›¤ï¼ˆå·²ç™¼ç”Ÿï¼‰
        "ath_date":      datetime(2025, 1, 20),
        "bear_low":      None,               # å°šæœªå®Œæˆ
        "bear_low_date": None,
        "peak_mult":     1.70,               # 108268 / 63842ï¼ˆå·²çŸ¥ï¼‰
        "bottom_mult":   None,               # å°šæœªå®Œæˆ
        "peak_days":     276,                # 2024-04-19 â†’ 2025-01-20
        "bottom_days":   None,               # å°šæœªå®Œæˆ
        "is_complete":   False,              # é€²è¡Œä¸­
    },
]

# â”€â”€ åªå–å·²å®Œæˆé€±æœŸè¨ˆç®—çµ±è¨ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
_completed = [c for c in CYCLE_HISTORY if c["is_complete"]]
_peak_mults       = [c["peak_mult"]    for c in _completed]
_bottom_mults     = [c["bottom_mult"]  for c in _completed]
_peak_days_list   = [c["peak_days"]    for c in _completed]
_bottom_days_list = [c["bottom_days"]  for c in _completed]

STATS = {
    "peak_mult_median":   float(np.exp(np.median(np.log(_peak_mults)))),
    "peak_mult_p25":      float(np.exp(np.percentile(np.log(_peak_mults), 25))),
    "peak_mult_p75":      float(np.exp(np.percentile(np.log(_peak_mults), 75))),
    "bottom_mult_median": float(np.median(_bottom_mults)),
    "bottom_mult_p25":    float(np.percentile(_bottom_mults, 25)),  # è·Œæ›´æ·±ï¼ˆæ‚²è§€ï¼‰
    "bottom_mult_p75":    float(np.percentile(_bottom_mults, 75)),  # è·Œè¼ƒæ·ºï¼ˆæ¨‚è§€ï¼‰
    "peak_days_median":   int(np.median(_peak_days_list)),
    "bottom_days_median": int(np.median(_bottom_days_list)),
}


def _tz_safe_timestamp(dt: datetime) -> pd.Timestamp:
    """
    å°‡ naive datetime è½‰ç‚º UTC-aware pd.Timestampï¼Œ
    é¿å…èˆ‡ tz-aware df.index æ¯”è¼ƒæ™‚éœé»˜å…¨ True æˆ–æ‹‹å‡º TypeErrorã€‚
    """
    if dt.tzinfo is None:
        return pd.Timestamp(dt, tz="UTC")
    return pd.Timestamp(dt)


def _strip_tz(df: pd.DataFrame) -> pd.DataFrame:
    """è‹¥ df.index æœ‰ timezoneï¼Œå»é™¤å¾Œå›å‚³ copyï¼ˆä¿æŒ naive DatetimeIndexï¼‰ã€‚"""
    if df.index.tz is not None:
        df = df.copy()
        df.index = df.index.tz_localize(None)
    return df


def analyze_market_state(current_price: float, df: pd.DataFrame, current_halving: datetime):
    """
    åˆ†æçœŸå¯¦å¸‚å ´ç‹€æ…‹ã€‚

    [v1.3 ä¿®æ­£] df.index tz æ¨™æº–åŒ–ï¼Œé¿å… naive vs tz-aware æ¯”è¼ƒéŒ¯èª¤ã€‚

    è¿”å› dict:
      cycle_ath         : ç•¶å‰é€±æœŸï¼ˆæ¸›åŠå¾Œï¼‰æœ€é«˜æ”¶ç›¤åƒ¹
      cycle_ath_date    : ATH æ—¥æœŸ
      drawdown_from_ath : å¾ ATH è·Œå¹…ï¼ˆè² å€¼ï¼Œ-0.18 = è·Œ 18%ï¼‰
      sma200            : 200 æ—¥å‡ç·š
      price_vs_sma200   : current_price / sma200
      is_above_sma200   : æ˜¯å¦åœ¨å¹´ç·šä¸Šæ–¹
    """
    result = {
        "cycle_ath":         current_price,
        "cycle_ath_date":    datetime.utcnow(),
        "drawdown_from_ath": 0.0,
        "price_vs_sma200":   1.0,
        "sma200":            current_price,
        "is_above_sma200":   True,
    }

    if df is None or df.empty or "close" not in df.columns:
        return result

    # â–¸ çµ±ä¸€å»é™¤ timezoneï¼Œé¿å…æ¯”è¼ƒå¤±æ•—
    df_naive = _strip_tz(df)
    halving_ts = pd.Timestamp(current_halving)  # naive

    mask_cycle = df_naive.index >= halving_ts
    if mask_cycle.any():
        cycle_data   = df_naive.loc[mask_cycle, "close"]
        cycle_ath    = float(cycle_data.max())
        cycle_ath_dt = cycle_data.idxmax().to_pydatetime()
        result["cycle_ath"]      = cycle_ath
        result["cycle_ath_date"] = cycle_ath_dt

    result["drawdown_from_ath"] = (current_price - result["cycle_ath"]) / result["cycle_ath"]

    sma200 = (float(df_naive["close"].rolling(200).mean().iloc[-1])
              if len(df_naive) >= 200
              else float(df_naive["close"].mean()))
    result["sma200"]          = sma200
    result["price_vs_sma200"] = current_price / sma200 if sma200 > 0 else 1.0
    result["is_above_sma200"] = current_price > sma200

    return result


def _derive_real_season(time_season, drawdown, is_above_sma200, month_in_cycle):
    """
    æ ¹æ“šçœŸå¯¦å¸‚å ´ç‹€æ…‹æ¨å°æœ‰æ•ˆå­£ç¯€ã€‚
    è¿”å›: (real_season, real_season_zh, real_emoji, correction_reason, is_corrected)
    """
    if drawdown < -0.30 and not is_above_sma200:
        reason = (f"âš ï¸ å¸‚å ´æ ¡æ­£ï¼šå¾ç•¶å‰é€±æœŸ ATH è·Œå¹… {abs(drawdown)*100:.1f}%ï¼Œ"
                  f"å·²è·Œç ´å¹´ç·šï¼Œå¯¦éš›è™•æ–¼æ·±ç†Šï¼ˆå†¬å­£ï¼‰ã€‚æ™‚é–“å­£ç¯€ï¼ˆ{time_season}ï¼‰åƒ…ä¾›åƒè€ƒã€‚")
        return "winter", "å†¬å­£ â€” æ·±ç†Šåº•éƒ¨", "â„ï¸", reason, time_season not in ("autumn", "winter")

    if drawdown < -0.20 and not is_above_sma200:
        reason = (f"âš ï¸ å¸‚å ´æ ¡æ­£ï¼šå¾ç•¶å‰é€±æœŸ ATH è·Œå¹… {abs(drawdown)*100:.1f}%ï¼Œ"
                  f"å·²è·Œç ´å¹´ç·šï¼Œå¯¦éš›è™•æ–¼ç†Šå¸‚åˆæœŸï¼ˆç§‹å­£ï¼‰ã€‚æ™‚é–“å­£ç¯€ï¼ˆ{time_season}ï¼‰åƒ…ä¾›åƒè€ƒã€‚")
        return "autumn", "ç§‹å­£ â€” ç†Šå¸‚åˆæœŸ", "ğŸ‚", reason, time_season not in ("autumn", "winter")

    if drawdown < -0.15 and not is_above_sma200 and time_season in ("spring", "summer"):
        reason = (f"âš ï¸ å¸‚å ´æ ¡æ­£ï¼šæ™‚é–“ä½ç½®ç‚º{time_season}ï¼ˆæœˆ{month_in_cycle}ï¼‰ï¼Œ"
                  f"ä½†è·Œå¹… {abs(drawdown)*100:.1f}% ä¸”è·Œç ´å¹´ç·šï¼Œæå‰é€²å…¥ç§‹å­£ä¿®æ­£ã€‚")
        return "autumn", "ç§‹å­£ â€” æå‰å…¥ç§‹", "ğŸ‚", reason, True

    if drawdown < -0.10 and not is_above_sma200 and time_season in ("spring", "summer"):
        reason = (f"âš ï¸ å¸‚å ´è­¦ç¤ºï¼šè·Œå¹… {abs(drawdown)*100:.1f}% ä¸”è·Œç ´å¹´ç·šï¼Œ"
                  f"ç‰›å¸‚å‹•èƒ½å—é˜»ï¼Œä»¥ç§‹å­£ä¿®æ­£è¦–è§’é æ¸¬ã€‚")
        return "autumn", "ç§‹å­£ â€” ç‰›å¸‚å—é˜»", "ğŸ‚", reason, True

    label_map = {
        "spring": ("æ˜¥å­£ â€” å¾©ç”¦æœŸ",   "ğŸŒ±"),
        "summer": ("å¤å­£ â€” ç‰›å¸‚é«˜å³°", "â˜€ï¸"),
        "autumn": ("ç§‹å­£ â€” æ³¡æ²«ç ´è£‚", "ğŸ‚"),
        "winter": ("å†¬å­£ â€” ç†Šå¸‚åº•éƒ¨", "â„ï¸"),
    }
    s_zh, emoji = label_map.get(time_season, ("æœªçŸ¥", "â“"))
    return time_season, s_zh, emoji, None, False


def get_current_season(as_of: datetime = None):
    """è¨ˆç®—ã€Œæ™‚é–“å­£ç¯€ã€ï¼ˆç´”æ¸›åŠé€±æœŸæ™‚é–“ä½ç½®ï¼Œä¸å«å¸‚å ´æ ¡æ­£ï¼‰ã€‚"""
    if as_of is None:
        as_of = datetime.utcnow()

    past_halvings = [h for h in HALVING_DATES if h <= as_of]
    if not past_halvings:
        return None
    current_halving = past_halvings[-1]

    future_halvings = [h for h in HALVING_DATES if h > as_of]
    next_halving    = future_halvings[0] if future_halvings else current_halving + timedelta(days=1460)

    days_since     = (as_of - current_halving).days
    days_total     = (next_halving - current_halving).days
    days_to_next   = (next_halving - as_of).days
    month_in_cycle = int(days_since / 30.44)
    cycle_progress = min(days_since / days_total, 1.0)

    if month_in_cycle < 12:
        season, season_zh, emoji = "spring", "æ˜¥å­£ â€” å¾©ç”¦æœŸ", "ğŸŒ±"
    elif month_in_cycle < 24:
        season, season_zh, emoji = "summer", "å¤å­£ â€” ç‰›å¸‚é«˜å³°", "â˜€ï¸"
    elif month_in_cycle < 36:
        season, season_zh, emoji = "autumn", "ç§‹å­£ â€” æ³¡æ²«ç ´è£‚", "ğŸ‚"
    else:
        season, season_zh, emoji = "winter", "å†¬å­£ â€” ç†Šå¸‚åº•éƒ¨", "â„ï¸"

    return {
        "season":         season,
        "season_zh":      season_zh,
        "emoji":          emoji,
        "halving_date":   current_halving,
        "next_halving":   next_halving,
        "days_since":     days_since,
        "days_to_next":   days_to_next,
        "cycle_progress": cycle_progress,
        "month_in_cycle": month_in_cycle,
    }


def _apply_diminishing_returns(base_mult: float, cycle_index: int) -> float:
    """æ¯å€‹é€±æœŸç‰›å¸‚æ¼²å¹…éæ¸›ç´„ 3.5 å€ï¼Œä»¥æœ€å¾Œä¸€å€‹å®Œæˆé€±æœŸç‚ºåŸºæº–å¤–æ’ã€‚"""
    diminish_factor = 3.5
    ref_cycle = len(_completed) - 1  # æœ€å¾Œä¸€å€‹å®Œæˆé€±æœŸ index
    delta = cycle_index - ref_cycle
    if delta <= 0:
        return base_mult
    return base_mult / (diminish_factor ** delta)


def forecast_price(current_price: float, df: pd.DataFrame = None, as_of: datetime = None):
    """
    ä¸»è¦é æ¸¬å‡½æ•¸ã€‚æ•´åˆæ™‚é–“å­£ç¯€ + çœŸå¯¦å¸‚å ´ç‹€æ…‹ï¼Œé æ¸¬æœªä¾†12å€‹æœˆç›®æ¨™åƒ¹ã€‚

    [v1.3] ä¿®æ­£ï¼š
    - df tz æ¨™æº–åŒ–ç§»è‡³ analyze_market_stateï¼ˆçµ±ä¸€è™•ç†ï¼‰
    - prev_ath è¨ˆç®—ä¹ŸåŠ  tz æ¨™æº–åŒ–ä¿è­·
    - ç†Šå¸‚æ¨™ç±¤æ”¹ç‚ºï¼šdeepestï¼ˆæœ€æ·±ï¼‰/ medianï¼ˆä¸­ä½æ•¸ï¼‰/ shallowestï¼ˆæœ€æ·ºï¼‰

    è¿”å› dict é¡å¤–æ¬„ä½ï¼ˆv1.3 æ–°å¢ï¼‰:
      bear_label_low    : ç†Šå¸‚ä¸‰æ¨™ç±¤ï¼ˆã€Œæœ€æ·±ç›®æ¨™ã€ç­‰ï¼‰
      bear_label_mid    : ç†Šå¸‚ä¸­é–“æ¨™ç±¤
      bear_label_high   : ç†Šå¸‚æœ€æ·ºæ¨™ç±¤
    """
    if as_of is None:
        as_of = datetime.utcnow()

    season_info = get_current_season(as_of)
    if season_info is None:
        return None

    current_halving   = season_info["halving_date"]
    current_cycle_idx = HALVING_DATES.index(current_halving)

    halving_price = current_price
    prev_ath      = None

    if df is not None and not df.empty and "close" in df.columns:
        df_naive = _strip_tz(df)  # â–¸ tz æ¨™æº–åŒ–
        halving_ts = pd.Timestamp(current_halving)

        halving_mask = df_naive.index >= halving_ts
        if halving_mask.any():
            halving_price = float(df_naive.loc[halving_mask, "close"].iloc[0])

        if current_cycle_idx > 0:
            prev_halving = HALVING_DATES[current_cycle_idx - 1]
            mask_prev    = (df_naive.index >= pd.Timestamp(prev_halving)) & \
                           (df_naive.index <  halving_ts)
            if mask_prev.any():
                prev_ath = float(df_naive.loc[mask_prev, "close"].max())

    # å·²çŸ¥ç¬¬4é€±æœŸ ATH å‚™æ´ï¼šè‹¥ prev_ath å–åˆ°çš„æ˜¯å‰ä¸€é€±æœŸï¼Œä½†ç•¶å‰é€±æœŸå·²æœ‰æ›´é«˜çš„ ATH
    # cycle_history ä¸­è‹¥æœ‰ç•¶å‰é€±æœŸçš„å·²çŸ¥ ATHï¼Œå„ªå…ˆæ¡ç”¨
    known_cycle = next((c for c in CYCLE_HISTORY if c["halving"] == current_halving), None)
    known_cycle_ath = known_cycle["ath_price"] if known_cycle and known_cycle["ath_price"] else None

    if prev_ath is None:
        prev_ath = CYCLE_HISTORY[-2]["ath_price"] if len(CYCLE_HISTORY) >= 2 else 68789.0

    market_state = analyze_market_state(current_price, df, current_halving)

    real_season, real_season_zh, real_emoji, correction_reason, is_corrected = _derive_real_season(
        time_season     = season_info["season"],
        drawdown        = market_state["drawdown_from_ath"],
        is_above_sma200 = market_state["is_above_sma200"],
        month_in_cycle  = season_info["month_in_cycle"],
    )

    effective_season = {
        "season":    real_season,
        "season_zh": real_season_zh,
        "emoji":     real_emoji,
    }

    adj_peak_med = _apply_diminishing_returns(STATS["peak_mult_median"], current_cycle_idx)
    adj_peak_p25 = _apply_diminishing_returns(STATS["peak_mult_p25"],    current_cycle_idx)
    adj_peak_p75 = _apply_diminishing_returns(STATS["peak_mult_p75"],    current_cycle_idx)

    days_since = season_info["days_since"]

    if real_season in ("spring", "summer"):
        # â•â•â• ç‰›å¸‚é æ¸¬ â•â•â•
        forecast_type = "bull_peak"

        ath_target_med = halving_price * adj_peak_med
        ath_target_p25 = halving_price * adj_peak_p25
        ath_target_p75 = halving_price * adj_peak_p75

        if current_price > ath_target_med:
            remaining_mult = adj_peak_p75 / adj_peak_med
            ath_target_med = current_price * remaining_mult
            ath_target_p75 = ath_target_med * 1.3
            ath_target_p25 = ath_target_med * 0.75

        target_median = max(ath_target_med, current_price)
        target_low    = max(ath_target_p25, current_price)   # ç‰›å¸‚ï¼šä½ = ä¿å®ˆ = æ¼²å¹…å°
        target_high   = max(ath_target_p75, current_price)   # ç‰›å¸‚ï¼šé«˜ = æ¨‚è§€ = æ¼²å¹…å¤§

        days_to_peak   = max(STATS["peak_days_median"] - days_since, 30)
        estimated_date = as_of + timedelta(days=days_to_peak)

        rationale = (
            f"ã€æœ‰æ•ˆå­£ç¯€ã€‘{real_emoji} {real_season_zh}\n"
            f"æ™‚é–“ä½ç½®ï¼šç¬¬ {current_cycle_idx+1} æ¬¡æ¸›åŠå¾Œç¬¬ {season_info['month_in_cycle']} å€‹æœˆ\n"
            f"æ­·å²ä¸­ä½æ•¸ï¼šæ¸›åŠå¾Œç´„ {STATS['peak_days_median']} å¤©é”ç‰›å¸‚é«˜é»ï¼Œ"
            f"ç›¸å°æ¸›åŠåƒ¹æ¼²å¹…ä¸­ä½æ•¸ {adj_peak_med:.1f}x\n"
            f"æ¸›åŠæ™‚åƒ¹æ ¼: ${halving_price:,.0f}\n"
            f"é è¨ˆç‰›å¸‚é«˜é»å€é–“: ${target_low:,.0f} ~ ${target_high:,.0f}"
        )

        confidence = min(int(80 - abs(days_since - STATS["peak_days_median"]) / 5), 85)
        confidence = max(confidence, 40)
        if market_state["drawdown_from_ath"] < -0.10:
            confidence = max(confidence - 15, 25)

        bear_label_low  = "ä¿å®ˆç›®æ¨™ï¼ˆæ¼²å¹…è¼ƒå°ï¼‰"
        bear_label_mid  = "ä¸­ä½æ•¸ç›®æ¨™"
        bear_label_high = "æ¨‚è§€ç›®æ¨™ï¼ˆæ¼²å¹…è¼ƒå¤§ï¼‰"

    else:
        # â•â•â• ç†Šå¸‚é æ¸¬ â•â•â•
        forecast_type = "bear_bottom"

        # â–¸ å„ªå…ˆä½¿ç”¨ç•¶å‰é€±æœŸå·²çŸ¥ ATHï¼ˆCYCLE_HISTORYï¼‰
        # â–¸ å…¶æ¬¡ä½¿ç”¨ market_state è¨ˆç®—çš„ cycle_athï¼ˆå¾ df å–å¾—ï¼‰
        # â–¸ æœ€å¾Œæ‰ç”¨ prev_ath
        cycle_ath_ms = market_state.get("cycle_ath", 0)

        if known_cycle_ath and known_cycle_ath > current_price * 1.05:
            ath_ref       = known_cycle_ath
            ath_ref_label = f"ç•¶å‰é€±æœŸå·²çŸ¥ ATH ${known_cycle_ath:,.0f} (2025-01-20)"
        elif cycle_ath_ms and cycle_ath_ms > current_price * 1.05:
            ath_ref       = cycle_ath_ms
            ath_ref_label = f"ç•¶å‰é€±æœŸè¨ˆç®— ATH ${cycle_ath_ms:,.0f}"
        else:
            ath_ref       = prev_ath
            ath_ref_label = f"å‰ä¸€é€±æœŸ ATH ${prev_ath:,.0f}ï¼ˆç•¶å‰é€±æœŸATHå°šä¸æ˜ç¢ºï¼‰"

        bottom_med = ath_ref * STATS["bottom_mult_median"]  # ä¸­ä½æ•¸åº•éƒ¨
        bottom_p25 = ath_ref * STATS["bottom_mult_p25"]     # è·Œæ›´æ·±ï¼ˆæ‚²è§€ï¼‰
        bottom_p75 = ath_ref * STATS["bottom_mult_p75"]     # è·Œè¼ƒæ·ºï¼ˆæ¨‚è§€ï¼‰

        # ç†Šå¸‚ï¼šmin æˆªæ–·ï¼ˆåº•éƒ¨ä¸å¯èƒ½é«˜æ–¼ç¾åƒ¹ï¼‰
        target_median = min(bottom_med, current_price)
        target_low    = min(bottom_p25, current_price)   # ç†Šå¸‚ï¼šlow = æœ€æ‚²è§€ = è·Œæœ€æ·±
        target_high   = min(bottom_p75, current_price)   # ç†Šå¸‚ï¼šhigh = æœ€æ¨‚è§€ = è·Œæœ€æ·º

        days_to_bottom = max(STATS["bottom_days_median"] - days_since, 30)
        estimated_date = as_of + timedelta(days=days_to_bottom)

        drawdown_pct = abs(market_state["drawdown_from_ath"]) * 100
        rationale = (
            f"ã€æœ‰æ•ˆå­£ç¯€ã€‘{real_emoji} {real_season_zh}\n"
            f"æ™‚é–“ä½ç½®ï¼šç¬¬ {current_cycle_idx+1} æ¬¡æ¸›åŠå¾Œç¬¬ {season_info['month_in_cycle']} å€‹æœˆ "
            f"ï¼ˆæ™‚é–“å­£ç¯€ï¼š{season_info['season_zh']}ï¼‰\n"
            f"è· ATH è·Œå¹…: {drawdown_pct:.1f}%  |  "
            f"{'è·Œç ´' if not market_state['is_above_sma200'] else 'ç«™ä¸Š'} 200æ—¥å‡ç·š "
            f"(${market_state['sma200']:,.0f})\n"
            f"åƒè€ƒåŸºæº–: {ath_ref_label}\n"
            f"æ­·å²åº•éƒ¨è·Œå¹…ä¸­ä½æ•¸ {(1-STATS['bottom_mult_median'])*100:.0f}%ï¼ˆå¾ATHè¨ˆï¼‰\n"
            f"é è¨ˆç†Šå¸‚åº•éƒ¨å€é–“: ${target_low:,.0f} ~ ${target_high:,.0f}"
        )

        confidence = min(int(80 - abs(days_since - STATS["bottom_days_median"]) / 5), 80)
        confidence = max(confidence, 35)
        if market_state["drawdown_from_ath"] < -0.25:
            confidence = min(confidence + 10, 75)

        # â–¸ v1.3: ç†Šå¸‚æ¨™ç±¤æ”¹ç‚ºæ–¹å‘æ˜ç¢ºçš„æè¿°
        bear_label_low  = "æœ€æ·±ç›®æ¨™ï¼ˆæ­·å²æœ€å¤§è·Œå¹…ï¼‰"
        bear_label_mid  = "ä¸­ä½æ•¸ç›®æ¨™ï¼ˆæ­·å²å¹³å‡ï¼‰"
        bear_label_high = "æœ€æ·ºç›®æ¨™ï¼ˆæœ€è¼•å¾®ç†Šå¸‚ï¼‰"

    return {
        "season_info":         season_info,
        "market_state":        market_state,
        "effective_season":    effective_season,
        "forecast_type":       forecast_type,
        "target_median":       round(target_median, 0),
        "target_low":          round(target_low,    0),
        "target_high":         round(target_high,   0),
        "estimated_date":      estimated_date,
        "rationale":           rationale,
        "confidence":          confidence,
        "current_cycle_idx":   current_cycle_idx,
        "halving_price":       round(halving_price, 0),
        "prev_ath":            round(prev_ath, 0) if prev_ath else None,
        "is_season_corrected": is_corrected,
        "correction_reason":   correction_reason,
        "bear_label_low":      bear_label_low,
        "bear_label_mid":      bear_label_mid,
        "bear_label_high":     bear_label_high,
        "ath_ref":             round(ath_ref, 0) if forecast_type == "bear_bottom" else None,
    }


def get_cycle_comparison_table():
    """
    è¿”å›æ­·å²å„é€±æœŸæ¯”è¼ƒè¡¨ (pd.DataFrame)ã€‚
    [v1.3] ç¬¬4é€±æœŸæ¨™ã€Œé€²è¡Œä¸­ã€ï¼Œé¡¯ç¤ºå·²çŸ¥ATHï¼Œåº•éƒ¨æ¬„ä½é¡¯ç¤ºã€Œå°šæœªå®Œæˆã€ã€‚
    """
    rows = []
    for i, c in enumerate(CYCLE_HISTORY):
        if c["is_complete"]:
            rows.append({
                "é€±æœŸ":        f"ç¬¬ {i+1} æ¬¡æ¸›åŠ",
                "ç‹€æ…‹":        "âœ… å®Œæˆ",
                "æ¸›åŠæ—¥":      c["halving"].strftime("%Y-%m-%d"),
                "æ¸›åŠæ™‚åƒ¹æ ¼":  f"${c['halving_price']:,.0f}",
                "ç‰›å¸‚ ATH":    f"${c['ath_price']:,.0f}",
                "ATH å€æ•¸":    f"{c['peak_mult']:.1f}x",
                "é” ATH å¤©æ•¸": f"{c['peak_days']} å¤©",
                "ç†Šå¸‚æœ€ä½é»":  f"${c['bear_low']:,.0f}",
                "ATH è·Œå¹…":    f"{(1-c['bottom_mult'])*100:.0f}%",
                "é”åº•éƒ¨å¤©æ•¸":  f"{c['bottom_days']} å¤©",
            })
        else:
            rows.append({
                "é€±æœŸ":        f"ç¬¬ {i+1} æ¬¡æ¸›åŠ",
                "ç‹€æ…‹":        "ğŸ”„ é€²è¡Œä¸­",
                "æ¸›åŠæ—¥":      c["halving"].strftime("%Y-%m-%d"),
                "æ¸›åŠæ™‚åƒ¹æ ¼":  f"${c['halving_price']:,.0f}",
                "ç‰›å¸‚ ATH":    f"${c['ath_price']:,.0f} âœ“",
                "ATH å€æ•¸":    f"{c['peak_mult']:.2f}x",
                "é” ATH å¤©æ•¸": f"{c['peak_days']} å¤©",
                "ç†Šå¸‚æœ€ä½é»":  "â€”ï¼ˆå°šæœªå®Œæˆï¼‰",
                "ATH è·Œå¹…":    "â€”",
                "é”åº•éƒ¨å¤©æ•¸":  "â€”",
            })
    return pd.DataFrame(rows)


def get_power_law_forecast(df: pd.DataFrame, months_ahead: int = 12):
    """
    å†ªå¾‹æ¨¡å‹ï¼šæœªä¾† months_ahead å€‹æœˆçš„é•·æœŸå…¬å…åƒ¹å€¼èµ°å»Šã€‚

    å…¬å¼: Price = 10^(-17.01467 + 5.84 Ã— log10(days_since_genesis))
    ä¾†æº: Giovanni Santostasi æ¯”ç‰¹å¹£å†ªå¾‹ç†è«–
    èªªæ˜: æ­¤ç‚ºé•·æœŸè¶¨å‹¢ä¼°å€¼ï¼ŒéçŸ­æœŸç›®æ¨™ï¼Œä¸ä»£è¡¨çŸ­æœŸæœƒåˆ°é”è©²åƒ¹ä½ã€‚
          Â±0.45 å°æ•¸é€šé“å«è“‹æ­·å² 95%+ æ—¥ç·šæ”¶ç›¤ï¼Œåƒ…ä¾›é•·æœŸåƒè€ƒã€‚
    """
    genesis      = datetime(2009, 1, 3)
    future_dates = pd.date_range(
        start   = datetime.utcnow() + timedelta(days=1),
        periods = months_ahead * 30,
        freq    = "D",
    )
    days_arr   = np.array([(d.to_pydatetime() - genesis).days for d in future_dates], dtype=float)
    days_arr   = np.clip(days_arr, 1, None)
    log_median = -17.01467 + 5.84 * np.log10(days_arr)

    return pd.DataFrame({
        "median": 10 ** log_median,
        "upper":  10 ** (log_median + 0.45),
        "lower":  10 ** (log_median - 0.45),
    }, index=future_dates)